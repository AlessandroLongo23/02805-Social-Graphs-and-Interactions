# Week_7: Community Detection & Genre Analysis

This folder contains scripts for analyzing rock music performer networks, extracting genres from Wikipedia data, detecting communities using the Louvain algorithm, and comparing structural communities with genre-based classifications.

## üìÅ Files Overview

### Data Files
- `artist_genres.json` - Genre mappings for all performers (generated by `main.py`)
- `modularity_results.json` - Genre-based modularity scores (generated by `modularity_analysis.py`)
- `community_detection_results.json` - Louvain community results (generated by `community_detection.py`)
- `community_detection_results_partition.json` - Full partition data (generated by `community_detection.py`)
- `confusion_matrix_results.json` - Confusion matrix analysis (generated by `confusion_matrix_analysis.py`)

### Visualization Files
- `top_15_genres_histogram.png` - Top 15 genres by artist count
- `community_network_visualization.png` - Network colored by structural communities
- `confusion_matrix.png` - Heatmap comparing genres vs communities

### Script Files

## üîÑ Workflow: Run Scripts in This Order

### Part 1: Extract Genres from Wikipedia Data
```bash
python main.py
```

**What it does:**
- Parses Wikipedia infobox HTML from all performer JSON files
- Extracts and normalizes genre information
- Handles variations like "rock'n'roll", "rock & roll", etc.
- Generates statistics and histogram of top 15 genres

**Output:**
- `artist_genres.json` - Dictionary mapping artists to genre lists
- `top_15_genres_histogram.png` - Visualization
- Console statistics (number of artists, average genres, distinct genres)

**Requirements:**
- BeautifulSoup4: `pip install beautifulsoup4`
- Matplotlib: `pip install matplotlib`

---

### Part 2: Modularity Analysis (Genre-Based Communities)
```bash
python modularity_analysis.py
```

**What it does:**
- Implements **Equation 9.12** from the [Network Science book](http://networksciencebook.com/chapter/9)
- Calculates modularity for different genre assignment strategies:
  1. **First Genre**: Use the first genre in each artist's list
  2. **First Non-Rock Genre**: Use first genre that doesn't contain "rock"
  3. **Random Genre**: Randomly select from available genres
- Compares results to determine if genres form good communities

**Output:**
- `modularity_results.json` - Modularity scores for all strategies
- Console analysis with interpretation

**Key Concept - Modularity (M):**
```
M = 1/(2L) * Œ£(A_ij - k_i*k_j/(2L)) * Œ¥(c_i, c_j)
```
- M > 0.3: Strong community structure
- 0 < M < 0.3: Weak to moderate community structure
- M ‚âà 0: No better than random
- M < 0: Anti-community structure

**Requirements:**
- NetworkX: `pip install networkx`
- NumPy: `pip install numpy`

---

### Part 2 (continued): Structural Community Detection (Louvain Algorithm)
```bash
python community_detection.py
```

**What it does:**
- Uses the **Louvain algorithm** to detect structural communities
- Works on the undirected network filtered to nodes with genre data
- Calculates modularity of detected communities
- Compares with genre-based modularity from Step 2
- Visualizes network with nodes colored by community
- Provides detailed interpretation

**Output:**
- `community_detection_results.json` - Community statistics and top 10 communities
- `community_detection_results_partition.json` - Full node‚Üícommunity mapping
- `community_network_visualization.png` - Network visualization
- Console analysis and interpretation

**Visualization Features:**
- Colors the 10 largest communities with distinct colors
- Remaining nodes shown in light gray
- Uses **ForceAtlas2 layout** from NetworkX (with fallback to spring layout)
- Includes legend showing community sizes
- **NEW:** Backbone extraction and visualization to reveal core structure

**Requirements:**
- NetworkX (‚â• 3.0): `pip install networkx`
- Matplotlib: `pip install matplotlib`

**Note on ForceAtlas2:**
- NetworkX 3.5+ includes `forceatlas2_layout` natively
- The script automatically falls back to spring layout if not available
- ForceAtlas2 provides better visualization for large networks

**Backbone Extraction:**
The script now automatically extracts and visualizes the network backbone:
- Uses **edge betweenness centrality** to identify important edges
- Keeps top 30% of edges by default (adjustable)
- Reveals core network structure without visual clutter
- Shows how communities correspond to the backbone structure

Reference: [NetworkX ForceAtlas2](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.layout.forceatlas2_layout.html)

---

### Part 2 (final): Confusion Matrix Analysis (Genres vs Communities)
```bash
python confusion_matrix_analysis.py
```

**What it does:**
- Creates a **confusion matrix D(G √ó C)** where:
  - G = 7 most common genres
  - C = 7 largest communities
  - D(i,j) = number of artists with genre i in community j
- Uses **all genres** for each artist (not just first genre)
- Calculates alignment metrics:
  - **Purity**: How homogeneous communities are by genre
  - **Completeness**: How concentrated genres are in communities
- Provides detailed interpretation

**Output:**
- `confusion_matrix.png` - Heatmap visualization
- `confusion_matrix_results.json` - Full matrix data and metrics
- Console analysis with row and column interpretations

**Key Metrics:**
- **Average Community Purity**: Higher = communities are genre-homogeneous
- **Average Genre Completeness**: Higher = genres concentrated in single communities
- **Max Overlap Score**: Ratio of artists in dominant communities for their genres

**Requirements:**
- NumPy: `pip install numpy`
- Matplotlib & Seaborn: `pip install matplotlib seaborn`

---

## üìä Expected Results

Based on typical rock music networks:

1. **Genre Extraction** (~500-600 artists with genres)
   - Rock is overwhelmingly the most common first genre
   - Average 2-4 genres per artist
   - 50-100 distinct genres total

2. **Genre-Based Modularity** (M ‚âà 0.1 - 0.3)
   - First genre: Low modularity (dominated by "rock")
   - First non-rock: Improved modularity
   - Random: Similar to non-rock strategy

3. **Structural Communities** (M ‚âà 0.3 - 0.5)
   - 10-30 major communities
   - Higher modularity than genre-based
   - Reveals network structure beyond genres

4. **Confusion Matrix**
   - Moderate alignment (purity & completeness ‚âà 0.4-0.6)
   - Some communities align with genres
   - Cross-genre connections are common

---

## üéØ Key Insights

### Why Structural Modularity > Genre Modularity?

The Louvain algorithm finds communities based on **actual network connections**, which are shaped by:
- **Collaborations** between artists
- **Musical influences** across genre boundaries
- **Era/time period** (70s rock, 90s grunge, etc.)
- **Geographic proximity** (Seattle scene, British Invasion, etc.)
- **Record labels** and producers

Genres are **external labels** that:
- May not capture all musical similarities
- Can be inconsistent across sources
- Often overlap (most artists have multiple genres)
- May not reflect actual collaboration patterns

### What Does the Confusion Matrix Tell Us?

- **Diagonal dominance**: Communities align well with genres
- **Scattered distribution**: Network transcends genre boundaries
- **Mixed communities**: Cross-genre musical movements
- **Genre concentration**: Some genres stay within communities

---

## üîß Troubleshooting

### Common Issues

1. **FileNotFoundError for partition file**
   - Solution: Run `community_detection.py` before `confusion_matrix_analysis.py`

2. **Memory errors with large networks**
   - Solution: Scripts optimize for networks with 500+ nodes
   - For very large networks (>2000 nodes), consider sampling

3. **Slow visualization**
   - Solution: Spring layout calculation can be slow for large networks
   - Consider reducing iterations or using a subset

4. **Import errors**
   - Solution: Install all required packages:
   ```bash
   pip install networkx numpy matplotlib seaborn beautifulsoup4
   ```

---

### Part 3: Term Frequency (TF) Analysis
```bash
python Week_7/term_frequency_analysis.py
```

**What it does:**
- Extracts Wikipedia text from all performer JSON files
- Aggregates text by the top 15 most common genres
- Cleans and tokenizes text (removes punctuation, stopwords, etc.)
- Calculates term frequency (TF) for each genre
- Processes multiple genre assignment methods for comparison

**Output:** (organized in separate directories per method)
- `tf_analysis_{method}/term_frequencies.json` - Word frequencies for each genre
- `tf_analysis_{method}/tf_summary.png` - Vocabulary size and word count visualizations

**Genre Assignment Methods:**
The script implements multiple strategies for handling artists with multiple genres:

1. **ALL_GENRES**: Count each artist's page for every genre they have
   - Most comprehensive
   - Captures all genre associations
   - May create overlap between genres

2. **FIRST_GENRE**: Use only the first genre in the list
   - Simplest method
   - Often dominated by 'rock'
   - Clean, non-overlapping assignments

3. **FIRST_NON_ROCK**: Use first genre that doesn't contain 'rock'
   - Attempts to capture more specific subgenres
   - Falls back to first genre if all contain 'rock'
   - Reduces rock's dominance

**Text Processing Pipeline:**
1. Extract HTML from performer JSON files
2. Convert HTML to clean text using BeautifulSoup
3. Tokenize using NLTK
4. Remove:
   - Punctuation and non-alphabetic characters
   - Stopwords (common words like 'the', 'a', 'is')
   - Words shorter than 3 characters
   - URLs and wiki-specific syntax
   - Words appearing less than 5 times
5. Convert to lowercase
6. (Optional) Lemmatization

**Requirements:**
- NLTK: `pip install nltk`
- BeautifulSoup4: `pip install beautifulsoup4`
- Matplotlib: `pip install matplotlib`

**Key Findings:**
- Top words are often generic (band, music, album, song)
- Without TF-IDF, frequency alone doesn't distinguish genres
- Different methods reveal different aspects of genre vocabulary
- Prepares data for TF-IDF analysis (Part 5) and word clouds (Part 4)

**Note:** The script automatically downloads required NLTK data (punkt, stopwords, wordnet) on first run.

---

### Part 4: Word Cloud Visualization
```bash
python Week_7/wordcloud_generator.py
```

**What it does:**
- Loads term frequency data from Part 3
- Converts TF dictionaries to text strings (repeating words by count)
- Creates beautiful word cloud visualizations for each genre
- Generates both individual and combined grid views

**Output:** (in `tf_analysis_{method}/wordclouds/`)
- Individual word cloud PNG for each of the 15 genres
- `all_genres_combined.png` - Grid view of all genres together
- Analysis of top words and observations

**Configuration:**
- Edit `selected_method` in the script to choose which TF analysis to visualize:
  - `'all_genres'` (default)
  - `'first_genre'`
  - `'first_non_rock'`

**Word Cloud Features:**
- **Size**: Larger words = higher frequency
- **Colors**: Rotating colormaps for visual variety (no semantic meaning)
- **Max words**: 200 for individual, 150 for grid
- **Collocations disabled**: Prevents artificial phrase detection (as recommended)
- High resolution output (300 DPI for individual, 200 DPI for grid)

**Key Observations:**
The word clouds will reveal:
1. **Generic dominance**: Words like "band", "album", "music", "song" dominate all genres
2. **Structural similarity**: Wikipedia articles follow similar patterns
3. **Limited discrimination**: TF alone can't distinguish what makes each genre unique
4. **Need for TF-IDF**: Pure frequency doesn't capture genre-specific vocabulary

**Why This Matters:**
Word clouds based on TF alone show what's FREQUENT, not what's CHARACTERISTIC.
This motivates Part 5 (TF-IDF), which will highlight truly distinctive words.

**Requirements:**
- WordCloud: `pip install wordcloud`
- Matplotlib: `pip install matplotlib`
- NumPy: `pip install numpy`

**Note on Installation:**
- The `wordcloud` package requires a C compiler on some systems
- Windows: Usually works with `pip install wordcloud`
- Mac: May need Xcode command line tools
- Linux: Usually works out of the box
- See [WordCloud GitHub](https://github.com/amueller/word_cloud) for details

---

## üìö References

1. **Network Science Book - Chapter 9**: http://networksciencebook.com/chapter/9
   - Modularity definition (Section 9.4, Equation 9.12)
   - Community detection algorithms
   - Interpretation guidelines

2. **Louvain Algorithm**: 
   - NetworkX Documentation: https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.louvain.louvain_communities.html
   - Original Paper: Blondel et al., "Fast unfolding of communities in large networks" (2008)

3. **ForceAtlas2 Layout**:
   - Paper: Jacomy et al., "ForceAtlas2, a Continuous Graph Layout Algorithm" (2014)
   - Alternative: NetworkX spring_layout (Fruchterman-Reingold)

---

## üöÄ Next Steps

After completing these analyses, you can:

1. **Part 3: TF-IDF Analysis**
   - Extract text from Wikipedia pages
   - Calculate term frequency for each genre/community
   - Use TF-IDF to find characteristic words

2. **Part 4: Word Clouds**
   - Create word clouds for each genre
   - Create word clouds for each community
   - Compare genre vs community characteristics

3. **Advanced Analysis**
   - Try different community detection algorithms (Infomap, Leiden)
   - Analyze backbone networks (disparity filter)
   - Temporal analysis if data includes active years
   - Centrality analysis to find influential artists

---

## üí° Tips for Analysis

1. **Always check data quality**
   - How many artists have genres?
   - Are genres well-distributed?
   - Is the network connected?

2. **Compare multiple methods**
   - Don't rely on a single modularity score
   - Look at visualizations
   - Consider domain knowledge

3. **Interpret in context**
   - What do the communities represent musically?
   - Do they align with known music history?
   - What factors beyond genre shape the network?

4. **Document your findings**
   - Save all visualizations
   - Record modularity scores
   - Note interesting patterns

---

## üìù Assignment Deliverables

Based on Week_7 notebook requirements:

**Part 1: Genre Extraction**
- [ ] Genres extracted and statistics reported
- [ ] Top 15 genres identified and visualized

**Part 2: Community Detection**
- [ ] Modularity explanation in your own words
- [ ] Modularity scores for 3 genre assignment strategies
- [ ] Discussion of findings
- [ ] Louvain communities detected and modularity reported
- [ ] Comparison: structural vs genre modularity
- [ ] Network visualization with communities colored (ForceAtlas2)
- [ ] Backbone visualization with communities
- [ ] Structural observations documented
- [ ] Confusion matrix created and visualized
- [ ] Confusion matrix interpretation provided

**Part 3: Term Frequency Analysis**
- [ ] Text extracted from Wikipedia pages
- [ ] Text aggregated by top 15 genres
- [ ] Term frequency lists created for each genre
- [ ] Top 15 words per genre identified
- [ ] Multiple genre assignment methods tested
- [ ] Comments on top words for each genre
- [ ] Vocabulary size and word count visualizations

**Part 4: Word Cloud Visualization**
- [ ] Word clouds created for all top 15 genres
- [ ] Individual word clouds saved (high resolution)
- [ ] Combined grid visualization created
- [ ] Observations documented on visual patterns
- [ ] Comments on why generic words dominate
- [ ] Multiple methods compared (optional)

---

## üéØ Quick Start

For the complete Week_7 analysis, run scripts in this order:

```bash
# Part 1: Extract genres
python Week_7/main.py

# Part 2: Community detection & modularity
python Week_7/modularity_analysis.py
python Week_7/community_detection.py
python Week_7/confusion_matrix_analysis.py

# Part 3: Text analysis
python Week_7/term_frequency_analysis.py

# Part 4: Visualize with word clouds
python Week_7/wordcloud_generator.py
```

---

Good luck with your analysis! üé∏üéµ

